#extract data from different APIs

import requests
import pandas as pd
import os

#First extraction is from the World Bank API

# Ensure "data" directory exists

os.makedirs("data", exist_ok=True)

# Define World Bank indicators and corresponding labels
wb_indicators = {
    "AG.YLD.CREL.KG": "crop_yield",
    "SN.ITK.DEFC.ZS": "food_insecurity",
    "NY.GDP.MKTP.CD": "GDP",
    "FP.CPI.TOTL.ZG": "Inflation",
    "SL.UEM.TOTL.ZS": "Unemployment",
    "SI.SPR.PCAP": "median_income",
    "EG.USE.PCAP.KG.OE": "energy_usage",
    "ER.H2O.FWTL.K3": "freshwater_withdrawal"
}

# Define countries
countries = "UKR;EGY;IRN;IRQ;ISR;JOR;LBN;SAU;SYR;TUR;ARE;YEM;KEN;NGA;ZAF;ETH;UGA;TZA;SDN"
year_range = "2000:2023"

def fetch_worldbank_data(indicator, indicator_name):
    """
    Fetches World Bank data for a specific indicator and saves it to CSV.
    
    Parameters:
        indicator (str): World Bank indicator code.
        indicator_name (str): Name of the indicator for CSV filename.
    """
    WB_URL = f"http://api.worldbank.org/v2/country/{countries}/indicator/{indicator}?format=json&date={year_range}"
    all_data = []
    page = 1  # Start from the first page

    while True:
        print(f"📡 Fetching {indicator_name} - Page {page}...")

        # Make API request with page parameter
        response = requests.get(f"{WB_URL}&page={page}").json()

        # Check if data exists in response
        if len(response) < 2 or "message" in response:
            print(f"❌ No more data available or error encountered for {indicator_name}.")
            break

        data = response[1]  # Extract actual data

        if not data:  # Stop if we reach an empty page
            break

        # Append data to list
        all_data.extend([
            {"country": d["country"]["value"], "year": d["date"], indicator_name: d["value"]}
            for d in data if d["value"] is not None
        ])

        # Stop if there are no more pages
        total_pages = response[0]["pages"]
        if page >= total_pages:
            break

        page += 1  # Increment to the next page

    # Convert to DataFrame and Save
    df = pd.DataFrame(all_data)
    file_path = f"data/worldbank_{indicator_name}.csv"
    df.to_csv(file_path, index=False)

    print(f"✅ {indicator_name} data saved to {file_path}!")

# Run the function for all indicators
for indicator, label in wb_indicators.items():
    fetch_worldbank_data(indicator, label)

print("✅ All World Bank Indicator Data Successfully Fetched & Saved!")
